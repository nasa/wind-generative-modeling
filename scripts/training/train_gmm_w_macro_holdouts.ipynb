{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c839fc-fa49-486d-a6c1-85f8962f096d",
   "metadata": {},
   "source": [
    "This notebook is looking at the GMM implementation with hold-out sets. Namely, for each combination of macro windspeed and direction, we hold out those observations from the data, train the GMM and then sample from the GMM for that held out category.\n",
    "\n",
    "GMM code is the same as that from `train_gmm.ipynb`.\n",
    "\n",
    "This notebook does the following things:\n",
    "1. Assembles the dataset\n",
    "2. Train the GMM models\n",
    "3. Generate and save samples using the emergent distribution from the sampling\n",
    "4. Looking at a sample to evaluate what is happening with the under sampling of some categories\n",
    "5. Generate a save samples with over-sampling to account for the under sampling of some categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7373e36-8c81-40aa-b636-70771c09cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3b50f-6e96-4e1a-b0a3-da6bfe74eb10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Assemble Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d341e8-a87e-4f0e-8f22-35380edd41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wd_s_to_uv(ws, wd):\n",
    "    \"\"\"\n",
    "    Translate wind speed and direction to (u,v).\n",
    "    \"\"\"\n",
    "    return -ws * np.sin(wd * (np.pi / 180.)), -ws * np.cos(wd * (np.pi / 180.))\n",
    "\n",
    "def wd_s_to_u(ws, wd):\n",
    "    \"\"\"\n",
    "    Translate wind speed and direction to u.\n",
    "    \"\"\"\n",
    "    return -ws * np.sin(wd * (np.pi / 180.))\n",
    "\n",
    "def wd_s_to_v(ws, wd):\n",
    "    \"\"\"\n",
    "    Translate wind speed and direction to v.\n",
    "    \"\"\"\n",
    "    return -ws * np.cos(wd * (np.pi / 180.))\n",
    "\n",
    "def uv_to_dir(u, v):\n",
    "    \"\"\"\n",
    "    Wind components --> direction\n",
    "    \"\"\"\n",
    "    sp = np.sqrt(u ** 2 + v ** 2)\n",
    "    u_prime, v_prime = u / sp, v / sp\n",
    "    return 360 - np.arccos(-v_prime) * (180 / np.pi)\n",
    "\n",
    "def deg_to_dir(deg):\n",
    "    \"\"\"\n",
    "    Translates from 360 degree to string direction\n",
    "    \"\"\"\n",
    "    if deg <= 22.5:\n",
    "        return 'NNE'\n",
    "    elif deg <= 45.:\n",
    "        return 'NE'\n",
    "    elif deg <= 67.5:\n",
    "        return 'ENE'\n",
    "    elif deg <= 90.:\n",
    "        return 'E'\n",
    "    elif deg <= 112.5:\n",
    "        return 'ESE'\n",
    "    elif deg <= 135.:\n",
    "        return 'SE'\n",
    "    elif deg <= 157.5:\n",
    "        return 'SSE'\n",
    "    elif deg <= 180.:\n",
    "        return 'S'\n",
    "    elif deg <= 202.5:\n",
    "        return 'SSW'\n",
    "    elif deg <= 225.:\n",
    "        return 'SW'\n",
    "    elif deg <= 247.5:\n",
    "        return 'WSW'\n",
    "    elif deg <= 270.:\n",
    "        return 'W'\n",
    "    elif deg <= 292.5:\n",
    "        return 'WNW'\n",
    "    elif deg <= 315.:\n",
    "        return 'NW'\n",
    "    elif deg <= 337.5:\n",
    "        return 'NNW'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def speed_num_to_str(speed):\n",
    "    \"\"\"\n",
    "    Converted computed windspeed to str category\n",
    "    \"\"\"\n",
    "    if speed <= 2.235:\n",
    "        return '(-0.001, 2.235]'\n",
    "    elif speed <= 5.364:\n",
    "        return '(2.235, 5.364]'\n",
    "    elif speed <= 8.047:\n",
    "        return '(5.364, 8.047]'\n",
    "    elif speed <= 15.646:\n",
    "        return '(8.047, 15.646]'\n",
    "    else:\n",
    "        return 'Uncategorized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3264bee-0910-4bed-85e6-684b075d19b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 255)\n",
      "(6542, 94)\n",
      "(6542, 255)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '../../data/combined_macro_micro_wind_data.csv'\n",
    "\n",
    "data = pd.read_csv(DATA_DIR)\n",
    "print(data.shape)\n",
    "\n",
    "# isolate U and V columns\n",
    "u_cols = [f'u{i}' for i in np.arange(20, 255, 5)]\n",
    "v_cols = [f'v{i}' for i in np.arange(20, 255, 5)]\n",
    "\n",
    "# create dataframe with just desired columns\n",
    "data_df = data[u_cols + v_cols].copy()\n",
    "data_df.dropna(inplace=True)\n",
    "print(data_df.shape)\n",
    "\n",
    "# store drop indices to modify the original dataset\n",
    "drop_idxs = data_df.dropna().index.values\n",
    "data = data.loc[drop_idxs]\n",
    "print(data.shape)\n",
    "\n",
    "# big dataset\n",
    "data_full = data_df.values\n",
    "\n",
    "# define the indices for the u and v components\n",
    "u_idxs = np.arange(47)\n",
    "v_idxs = np.arange(47, 94)\n",
    "\n",
    "# create dataframe for macro\n",
    "data_wind_macro = data[u_cols + v_cols].copy()\n",
    "\n",
    "# create columns for macro u and v\n",
    "data_wind_macro['u_macro'] = data.apply(lambda x: wd_s_to_u(ws=x['macro_ws'], wd=x['macro_wd']), axis=1)\n",
    "data_wind_macro['v_macro'] = data.apply(lambda x: wd_s_to_v(ws=x['macro_ws'], wd=x['macro_wd']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d66a449-fb4b-4460-add4-7dc74ccd4fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WSW' 'SW' 'WNW' 'W']\n",
      "['(-0.001, 2.235]' '(8.047, 15.646]' '(5.364, 8.047]' '(2.235, 5.364]']\n"
     ]
    }
   ],
   "source": [
    "# create lists of macro wind dir and speed\n",
    "macro_wind_dirs = data['macro_wd_str'].value_counts().index.values[:4]\n",
    "macro_wind_speeds = data['macro_ws_str'].value_counts().index.values\n",
    "print(macro_wind_dirs)\n",
    "print(macro_wind_speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed9bad2-18bc-4cf4-b0a1-445e14d54083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 16 masks to filter out every combo of top 4 wind dir and wind speeds\n",
    "macro_masks = np.zeros(shape=(data.shape[0], 16), dtype=bool)\n",
    "dir_speed_pairs = {}\n",
    "\n",
    "for i, dir in enumerate(macro_wind_dirs):\n",
    "    for j, speed in enumerate(macro_wind_speeds):\n",
    "        macro_masks[:, 4 * i + j] = ((data['macro_wd_str'] != dir) & (data['macro_ws_str'] != speed)).values\n",
    "        dir_speed_pairs[4 * i + j] = (dir, speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c600d-4b12-499e-ada5-47fd946fd4b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train GMM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610b77d2-6324-4546-85f3-7b764679d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ba2543-2f5c-4a3c-a290-0d0c78c767d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmm(data, num_pcs=7, num_comp=16, max_iter=200, n_init=15):\n",
    "    \"\"\"\n",
    "    Trains GMM by first performing a dimension reduction with PCA.\n",
    "\n",
    "    Returns GMM and necessary PCA components.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        data     (np arr) : N x p\n",
    "        num_pcs  (int)    : number of principal components\n",
    "        num_comp (int)    : number of GMM components\n",
    "        max_iter (int)    : max number of EM alg iterations\n",
    "        n_init   (int)    : number of EM initializations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        orth_pca_vecs (np arr) : num_pcs x p\n",
    "        x_bar         (np arr) : p\n",
    "        gm\n",
    "    \"\"\"\n",
    "    # compute principal components\n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "\n",
    "    # save orthogongal transformation -- \"h\" stands for \"high-dimensional\"\n",
    "    orth_pca_vecs = pca.components_[:num_pcs]\n",
    "    \n",
    "    # apply transformation to data\n",
    "    x_bar = data.mean(axis=0)\n",
    "    data_pca = (data - x_bar) @ orth_pca_vecs.T\n",
    "\n",
    "    # fit GMM\n",
    "    gm = GaussianMixture(\n",
    "        n_components=num_comp,\n",
    "        covariance_type='full',\n",
    "        max_iter=max_iter,\n",
    "        n_init=n_init\n",
    "    ).fit(data_pca)\n",
    "\n",
    "    return orth_pca_vecs, x_bar, gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ff6de2-08bf-4c5b-b01f-739cb952a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23975522580f4d0a8988e282af7c5c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the models\n",
    "NUM_PCS = 7\n",
    "NUM_GMM_COMPONENTS = 16\n",
    "pca_vecs = np.zeros(shape=(len(dir_speed_pairs), NUM_PCS, data_wind_macro.shape[1]))\n",
    "x_bars = np.zeros(shape=(len(dir_speed_pairs), data_wind_macro.shape[1]))\n",
    "gms = []\n",
    "\n",
    "for i in tqdm(range(len(dir_speed_pairs))):\n",
    "\n",
    "    # train the model\n",
    "    pca_vecs_i, x_bar_i, gm_i = train_gmm(\n",
    "        data_wind_macro.values[macro_masks[:, i], :],\n",
    "        num_pcs=NUM_PCS,\n",
    "        num_comp=NUM_GMM_COMPONENTS\n",
    "    )\n",
    "\n",
    "    # save the objects\n",
    "    pca_vecs[i] = pca_vecs_i\n",
    "    x_bars[i] = x_bar_i\n",
    "    gms.append(gm_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43fd5b57-4d2f-4836-b5ac-8c3d2742f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the above models\n",
    "for i in range(len(dir_speed_pairs)):\n",
    "\n",
    "    with open(f'../../models/gmm_hold_out_models/{''.join(dir_speed_pairs[i])}.pkl', 'wb') as f:\n",
    "        pickle.dump(obj=gms[i], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e57cb19-f241-4fc1-92b7-bda04e5329bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the above PCA objects\n",
    "for i in range(len(dir_speed_pairs)):\n",
    "\n",
    "    with open(f'../../models/gmm_hold_out_models/pca_obj_{''.join(dir_speed_pairs[i])}.npz', 'wb') as f:\n",
    "        np.savez(file=f, pca_vecs=pca_vecs[i], x_bars=x_bars[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3db63a-0e34-4187-91a7-d772331a5432",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Generate and save samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86023e64-9463-4789-9f49-184b73de1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "N = data_wind_macro.shape[0]\n",
    "data_sampled = np.zeros(shape=(len(dir_speed_pairs), N, data_wind_macro.shape[1]))\n",
    "\n",
    "for i in range(len(dir_speed_pairs)):\n",
    "\n",
    "    # sample from gmm -- \"ld\" == \"low-dimensional\"\n",
    "    sample_ld_i = gms[i].sample(n_samples=N)[0]\n",
    "\n",
    "    # project the sample to higher dimension\n",
    "    data_sampled[i] = sample_ld_i @ pca_vecs[i] + x_bars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c59fc-9ab4-4143-96a0-46074c8e3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain macro wind dir and speed for each sample\n",
    "sampled_macro_dir = np.zeros(shape=(16, N), dtype=np.object_)\n",
    "sampled_macro_speed = np.zeros(shape=(16, N))\n",
    "\n",
    "for i in range(16):\n",
    "    for j in range(N):\n",
    "\n",
    "        # direction\n",
    "        u_j, v_j = data_sampled[i, j, -2:]\n",
    "        sampled_macro_dir[i, j] = deg_to_dir(uv_to_dir(u=u_j, v=v_j))\n",
    "\n",
    "        # speed\n",
    "        sampled_macro_speed[i, j] = np.sqrt(u_j **2 + v_j ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c102ac-1529-48df-ad08-77a7fc1b29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data frame for each sample WITH macro dir and speed\n",
    "for i in range(16):\n",
    "    \n",
    "    # generate the data frame\n",
    "    df_i = pd.DataFrame(\n",
    "        data_sampled[0],\n",
    "        columns=u_cols + v_cols + ['macro_u', 'macro_v']\n",
    "    )\n",
    "    \n",
    "    df_i['macro_wd_str'] = sampled_macro_dir[i]\n",
    "    ws_i_ser = pd.Series(sampled_macro_speed[i])\n",
    "    df_i['macro_ws_str'] = ws_i_ser.apply(speed_num_to_str)\n",
    "\n",
    "    # save the data\n",
    "    dir_i, speed_i = dir_speed_pairs[i]\n",
    "    SAVE_PATH_I = f'../data/gmm_hold_out/{dir_i}_{speed_i}.csv'\n",
    "    df_i.to_csv(SAVE_PATH_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a8e24-ccef-4326-b07b-393cfb3f5295",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Over-sampling to achieve correct amounts of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244f76a-fffb-4b08-90e7-96c2c55ba668",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Calculate how many samples we need to obtain for each category\n",
    "2. For each category, sample from the corresponding model enough times to obtain enough samples in the held-out category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43efd128-430b-4efa-8b50-b78741857594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of sampels in each category\n",
    "category_counts = np.zeros(16, dtype=int)\n",
    "for i in range(16):\n",
    "    dir_i, speed_i = dir_speed_pairs[i]\n",
    "    category_counts[i] = ((data['macro_wd_str'] == dir_i) & (data['macro_ws_str'] == speed_i)).sum()\n",
    "    print(f'Category: {dir_i}-{speed_i} | Number of Samples: {category_counts[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b8c5c-5399-4f94-93f3-72d3b0c041e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gmm(gmm, num_samps, pca_vectors, x_bar):\n",
    "    \"\"\"\n",
    "    Sample GMM and compute macro directions and windspeeds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        gmm         (sklearn gmm model) : fitted model\n",
    "        num_samps   (int)               : total number of samples to generate\n",
    "        pca_vectors (np arr)            : pre-computed principal components\n",
    "        x_bar       (np arr)            : column averages of original design matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        df_sample (pd DataFrame)\n",
    "    \"\"\"\n",
    "    # sample from gmm -- \"ld\" == \"low-dimensional\"\n",
    "    sample_ld = gmm.sample(n_samples=num_samps)[0]\n",
    "\n",
    "    # project the sample to higher dimension\n",
    "    data_sampled = sample_ld @ pca_vectors + x_bar\n",
    "\n",
    "    macro_dir = np.zeros(num_samps, dtype=np.object_)\n",
    "    macro_speed = np.zeros(num_samps)\n",
    "    for j in range(num_samps):\n",
    "\n",
    "        # direction\n",
    "        u_j, v_j = data_sampled[j, -2:]\n",
    "        macro_dir[j] = deg_to_dir(uv_to_dir(u=u_j, v=v_j))\n",
    "\n",
    "        # speed\n",
    "        macro_speed[j] = np.sqrt(u_j **2 + v_j ** 2)\n",
    "\n",
    "    # create output dataframe\n",
    "    df_sample = pd.DataFrame(data_sampled, columns=u_cols + v_cols + ['macro_u', 'macro_v'])\n",
    "    df_sample['macro_wd_str'] = macro_dir\n",
    "    df_sample['macro_ws_str'] = macro_speed\n",
    "    df_sample['macro_ws_str'] = df_sample['macro_ws_str'].apply(speed_num_to_str)\n",
    "\n",
    "    return df_sample\n",
    "    \n",
    "\n",
    "def sample_gmm_until_enough(\n",
    "    gmm, num_samps, pca_vectors, x_bar,\n",
    "    total_num_samps, max_samp,\n",
    "    macro_dir, macro_speed\n",
    "):\n",
    "    \"\"\"\n",
    "    Samples from a given GMM model until enough samples have been obtained for\n",
    "    a particular category defined by macro_dir and macro_speed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        gmm             (sklearn gmm model) : fitted model\n",
    "        num_samps       (int)               : number of samples to generate on each attempt\n",
    "        pca_vectors     (np arr)            : pre-computed principal components\n",
    "        x_bar           (np arr)            : column averages of original design matrix\n",
    "        total_num_samps (int)               : the total number of desired samples\n",
    "        max_samp        (int)               : maximum number of samples to draw\n",
    "        macro_dir       (str)               : desired macro direction\n",
    "        macro_speed     (str)               : desired macro speed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        samples         (pd DataFrame) : actual samples\n",
    "        tot_num_samples (int)          : total number of generated samples (diagnostic)\n",
    "    \"\"\"\n",
    "    num_good_samples = 0\n",
    "    tot_num_samples = 0\n",
    "    samples = pd.DataFrame()\n",
    "    while (num_good_samples < total_num_samps) & (tot_num_samples < max_samp):\n",
    "\n",
    "        # generate data\n",
    "        df_sample = sample_gmm(\n",
    "            gmm=gmm,\n",
    "            num_samps=num_samps,\n",
    "            pca_vectors=pca_vectors,\n",
    "            x_bar=x_bar\n",
    "        )\n",
    "\n",
    "        # compute number of good samples\n",
    "        good_samples = df_sample.loc[(df_sample.macro_wd_str == macro_dir) & (df_sample.macro_ws_str == macro_speed)]\n",
    "\n",
    "        if good_samples.shape[0] > total_num_samps - num_good_samples:\n",
    "            good_samples = good_samples.iloc[:(total_num_samps - num_good_samples), :]\n",
    "\n",
    "        # add samples to output df\n",
    "        samples = pd.concat(\n",
    "            [samples, good_samples]\n",
    "        )\n",
    "\n",
    "        # update counter\n",
    "        num_good_samples = samples.shape[0]\n",
    "        tot_num_samples += num_samps\n",
    "\n",
    "    return samples.iloc[:total_num_samps], tot_num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a86a78-e17e-4dfb-88ff-074b09aeeb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the samples\n",
    "MAX_SAMP = int(1e8)\n",
    "sampled_dfs = [None] * 16\n",
    "tot_num_samples = np.zeros(16)\n",
    "for i in tqdm(range(16)):\n",
    "    dir_i, speed_i = dir_speed_pairs[i]\n",
    "    samples_test, tot_num_samples_test = sample_gmm_until_enough(\n",
    "        gmm=gms[i],\n",
    "        num_samps=data.shape[0],\n",
    "        pca_vectors=pca_vecs[i],\n",
    "        x_bar=x_bars[i],\n",
    "        total_num_samps=category_counts[i],\n",
    "        max_samp=MAX_SAMP,\n",
    "        macro_dir=dir_i,\n",
    "        macro_speed=speed_i\n",
    "    )\n",
    "\n",
    "    # save\n",
    "    sampled_dfs[i] = samples_test\n",
    "    tot_num_samples[i] = tot_num_samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72978b5c-a550-4a2b-bb96-32958a982301",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(np.arange(16), tot_num_samples)\n",
    "plt.yscale('log')\n",
    "plt.xticks(np.arange(16))\n",
    "plt.axhline(MAX_SAMP, linestyle='--', color='gray', label='Max num allowed samples')\n",
    "plt.title('Total number of draws to achieve sample')\n",
    "plt.xlabel('Group Number')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opt_intervals]",
   "language": "python",
   "name": "conda-env-opt_intervals-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
